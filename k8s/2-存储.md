# 存储

## 综述

`k8s`使用持久卷对存储进行抽象，使用`persistentVolum` (pv)描述当前的存储卷，使用`persistentVolumClaim` (pvc)描述所需的存储请求，另外引入`storageClass` (sc)描述提供存储服务的配置文件：包括各种策略和卷服务的供应商等。部署通过`pvc`描述所需存储空间、访问策略和`sc` (如果未指明使用`default sc`)，`k8s`通知`sc`指明的供应商程序，使其提供相应配置的`pv`卷，最后由调度器负责建立`pvc`与`pv`的映射关系，将指定的卷分配给部署。特别地，`pv`与`sc`是无命名空间对象，`pvc`属于特定的命名空间。

要为部署传递特定的信息方式有很多，从传递环境变量`env`、秘密`secret`、配置图`configMap`、临时存储`emptyDir`、本地卷`local`到网络文件系统`nfs`、云存储`ceph`和外部供应商的各种服务提供程序，种类各异，适配场景也有很大不同。下面会分别描述这些存储方式，以供进行部署时酌情选择。

## ENV

如下配置文件

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: demo
spec:
  containers:
  - name: demo
    image: bash
    resources:
      requests:
        cpu: "125m"
      limits:
        cpu: "250m"
    env:
    - name: ENV_KEY
      value: ENV_VALUE
    - name: PROTOCOL
      value: "https"
    - name: ADDRESS
      value: "$(PROTOCOL)://127.0.0.1:80"
    - name: MY_NODE_NAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName
    - name: MY_POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
    - name: MY_CPU_REQUEST
      valueFrom:
         resourceFieldRef:
           containerName: demo
           resource: request.cpu
    - name: MY_CPU_LIMIT
      valueFrom:
        resourceFieldRef:
          containerName: demo
          resource: limits.cpu
    command: ["echo"]
    args: ["$(ENV_KEY)"]
```

定义了环境变量`ENV_KEY=ENV_VALUE`，会在容器执行`echo ENV_VALUE`。如果列表预先定义了变量如`PROTOCOL`，则可以在后续依赖这个定义，`ADDRESS=https://127.0.0.1:80`。连续两个`$$`是转义符号。`MY_NODE_NAME`和`MY_POD_NAME`从`pod`中读取信息，`MY_CPU_REQUEST`和`MY_CPU_LIMIT`从`container`中读取信息。

如果容器希望获得更多自己的信息，也可以使用`downwardAPI`。

## Secret

已知`base64('my-app')=bXktYXBw`，`base64('39528$vdg7Jb')=Mzk1MjgkdmRnN0pi`

可以使用如下配置

```yaml
apiVersion: v1
kind: Secret
metadata:
  name: test
data:
  username: bXktYXBw
  password: Mzk1MjgkdmRnN0pi
```

或者如下命令

```bash
kubectl create secret generic test --from-literal='username=my-app' --from-literal='password=39528$vdg7Jb'
```

创建`secret`，特别地，`secret`属于特定的命名空间

可以使用卷访问`secret`

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: demo
spec:
  containers:
  - name: test
    image: nginx
    env:
    - name: USERNAME
      valueFrom:
        secretKeyRef:
          name: test
          key: username
    envFrom:
    - secretRef:
        name: test
    volumeMounts:
    - name: secret
      mountPath: /etc/secret
  volumes:
  - name: secret
    secret:
      secretName: test
```

这会在容器`/etc/secret`目录下建立两个文件`username`和`password`，分别对应数据条目`my-app`和`39528$vdg7Jb`。且设置环境变量`USERNAME=my-app`，`username=my-app`和`password=39528$vdg7Jb`。

另外，可以使用如下命令创建docker仓库令牌

```bash
kubectl create secret docker-registry <username> --docker-server=<server> --docker-username=<user> --docker-password=<password>
```

## ConfigMap

`configMap` (cm)可以将不大于`1M`的配置与镜像分离

可以使用如下命令从目录创建`configMap`，任何非普通文件的项目都会被忽略

```bash
kubectl create configmap <name> --from-file=<dir>
```

或者从多个文件创建`configMap`，特别地，`configMap`属于特定的命名空间

```bash
kubectl create configmap <name> --from-file=<file1> --from-file=<key>=<file2>
```

可以使用卷访问`configMap`

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: demo
spec:
  containers:
  - name: test
    image: busybox
    volumeMounts:
    - name: config
      mountPath: /etc/config
  volumes:
  - name: config
    configMap:
      name: config-name
```

这会将`configMap`挂载到`/etc/config`挂载点（原有文件将被删除）。当`configMap`发生更新时，已映射的键最终也会被更新，但是不会导致`pod`重启。如果服务不支持动态检测配置变更，则需要某种策略触发`pod`强制更新。

## EmptyDir

用于临时文件存储，当`pod`被从节点删除时，数据会被删除。特别地，容器崩溃不会导致`pod`从节点上移除，因此容器崩溃期间`emptyDir`中的数据是安全的。

使用以下配置来添加`emptyDir`

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: test
spec:
  containers:
  - image: busybox
    name: test
    volumeMounts:
    - mountPath: /cache
      name: cache
  volumes:
  - name: cache
    emptyDir: {}
```

## Local

`local`卷能够以持久和可移植的方式使用，系统通过查看`pv`的节点亲和性配置了解卷的节点约束。调度器使用该信息将使用`local`卷的`pod`调度到正确的节点。

通常需要手动清理和删除`local`类型的持久卷。

首先，使用以下配置创建`sc`

```yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: local-storage
provisioner: kubernetes.io/no-provisioner
volumeBindingMode: WaitForFirstConsumer
```

延迟卷绑定的操作可以确保`k8s`在为`pvc`作出绑定决策时，评估`pod`可能具有的其他节点约束，包括节点资源需求、节点选择器、Pod亲和性和反亲和性等。

在期望的节点创建pv卷

```yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  labels:
    type: data
  name: elasticsearch-data-0
spec:
  capacity:
    storage: 500G
  volumeMode: Filesystem
  accessModes:
  - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: local-storage
  local:
    path: /data/elasticsearch
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - aminer-dc-053
```

最后，定义`pvc`并在`pod`上挂载卷

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: data
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 500G
  selector:
    matchLabels:
      type: data
  storageClassName: local-storage
  volumeMode: Filesystem
  volumeName: elasticsearch-data-0
---
apiVersion: v1
kind: Pod
metadata:
  name: test
spec:
  containers:
  - image: busybox
    name: test
    volumeMounts:
    - mountPath: /cache
      name: cache
  volumes:
  - name: cache
    persistentVolumeClaim:
      claimName: data
```

`local`卷取决于底层节点的可用性，并不适合所有应用程序。如果节点变得不健康，由于绑定特性，`pod`不会被k8s从其他节点拉起，这将会阻止`pod`运行。另外，因底层磁盘问题可能带来潜在的数据丢失风险。`local`卷需要手动指明节点，规划存储，因此无法支撑大规模使用。

## NFS

`nfs`卷能将网络文件系统挂载到`pod`中。在删除`pod`时，`nfs`卷会被卸载而不是删除。可以预先填充数据，并且可以在`pod`之间共享。

可以使用`nfs-subdir-external-provisioner`供应商简化`nfs`配置，首先存储节点创建`nfs`服务

```bash
yum install nfs-utils -y

mkdir -p /data/nfs

vim /etc/exports
/data/nfs 192.168.6.0/24(rw,no_root_squash)

systemctl enable --now nfs
systemctl enable --now rpcbind

showmount -e
```

安装存储类

```bash
helm repo add nfs-subdir-external-provisioner https://kubernetes-sigs.github.io/nfs-subdir-external-provisioner/
docker.io/dyrnq/nfs-subdir-external-provisioner:v4.0.2
helm install nfs nfs-subdir-external-provisioner/nfs-subdir-external-provisioner --set nfs.server=192.168.6.147 --set nfs.path=/data/nfs --set storageClass.defaultClass=trueyum install nfs-utils -y
```

使用`pvc`声明所需存储

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: pvc
spec:
  accessModes:
  - ReadWriteMany
  resources:
    requests:
      storage: 100Gi
  storageClassName: nfs-client
```

相比于`local`卷，`nfs`卷对拉起`pod`的节点没有要求，因此当一个节点不再可用时，`k8s`可以在其他节点上重新拉起`pod`，只要`nfs`服务器没有问题，服务就能正常运行。这种方式有潜在的单点故障和瓶颈风险，与`local`卷一样，也存在因底层磁盘问题带来的潜在数据丢失风险。

## Ceph

以`ceph`为代表的云存储可以较好地适应`k8s`的云场景：支持多个存储节点，使用副本集或纠错码的方式进行冗余，在单个存储节点不可用时使用后备数据保证服务运行，可以动态扩容。代价是为支撑冗余而必须支付的额外存储、极大的内存和带宽需求以及强制的多节点需求 (`osd`不能在同故障域)。

安装使用操作符方式直接配置，需要至少2节点2未挂载卷支持[rook](https://rook.io/)

使用时根据`accessModes`不同选取不同的`sc`，`RWO`方式使用`rook-ceph-block`，`RWX`方式使用`rook-cephfs`

## 附录

### 磁盘挂载

使用xfs文件系统

```bash
fdisk -l
fdisk /dev/vdb
n
w

fdisk -l
mkfs.xfs /dev/vdb1
mkdir /data
mount /dev/vdb1 /data
df -hl

vim /etc/fstab
/dev/vdb1 /data xfs defaults 0 0
```

### 缩小分区

```bash
fuser -k -m /data
umount -f -R /data
e2fsck -f /dev/vdb1
resize2fs -p /dev/vdb1 1000G
fdisk /dev/vdb
p d p n +1000G p n p w
mount /dev/vdb1 /data
lsblk -f
```
